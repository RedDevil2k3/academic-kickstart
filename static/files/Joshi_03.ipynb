{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment-03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class complete_imdb_vocab:\n",
    "    def __init__(self, filename):\n",
    "        with open(filename, encoding=\"utf8\") as f:\n",
    "            self.words = f.read().splitlines()\n",
    "        self.inverted_index_map = {x: i for i, x in enumerate(self.words)}\n",
    "        self.stopwords = set(stopwords.words('english'))\n",
    "\n",
    "    def stopword_dict(self, word):\n",
    "        return word in self.stopwords\n",
    "\n",
    "    def indexed_stpwrds(self, index):\n",
    "        return self.words[index] in self.stopwords\n",
    "\n",
    "    def word_index(self, item):\n",
    "        return self.inverted_index_map.get(item, -1)\n",
    "    \n",
    "    \n",
    "    \n",
    "class Features:\n",
    "    reg_obj = re.compile(r\"((\\d+):(\\d+))\")\n",
    "\n",
    "    def __init__(self, num_rate: int, word_frequency: dict):\n",
    "        self.old_rating: int = num_rate\n",
    "        self.num_rate: int = 1 if num_rate > 5 else -1\n",
    "        self.word_frequency: dict = word_frequency.copy()\n",
    "\n",
    "    def __contains__(self, item):\n",
    "        return item in self.word_frequency\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.word_frequency.keys())\n",
    "\n",
    "    @classmethod\n",
    "    def read(cls, line: str):\n",
    "        line = line.split(None, 1)\n",
    "        num_rate = int(line[0])\n",
    "        words = '' if len(line) == 1 else line[1]\n",
    "        found = list(cls.reg_obj.finditer(words))\n",
    "\n",
    "        word_frequency = {}\n",
    "        for match in found:\n",
    "            index, times = match.group(2), match.group(3)\n",
    "            word_frequency[int(index)] = int(times)\n",
    "\n",
    "        return cls(num_rate, word_frequency)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "class Collection:\n",
    "    def __init__(self, reviews: list):\n",
    "        self.all = reviews.copy()\n",
    "        self.pos_review = [r for r in self.all if r.old_rating > 5]\n",
    "        self.neg_review = [r for r in self.all if r.old_rating < 5]\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.all)\n",
    "\n",
    "    @classmethod\n",
    "    def read(cls, filename: str):\n",
    "        reviews = []\n",
    "        with open(filename) as f:\n",
    "            for _, line in enumerate(f):\n",
    "                review = Features.read(line)\n",
    "                reviews.append(review)\n",
    "\n",
    "        return cls(reviews)\n",
    "\n",
    "    def shuffle(self):\n",
    "        copy = self.all.copy()\n",
    "        shuffle(copy)\n",
    "        return Collection(copy)\n",
    "\n",
    "    def total_count(self, index):\n",
    "        return sum(map(lambda x: index in x, self.all))\n",
    "\n",
    "    def count_positive(self, index):\n",
    "        return sum(map(lambda x: index in x, self.pos_review))\n",
    "\n",
    "    def count_negative(self, index):\n",
    "        return sum(map(lambda x: index in x, self.neg_review))\n",
    "\n",
    "    def copy(self):\n",
    "        return Collection(self.all)\n",
    "\n",
    "def multi_vald(l: list, levels):\n",
    "    z = len(l) // levels\n",
    "    for i in range(0, len(l), z):\n",
    "        test = l[i:i + z].copy()\n",
    "        train = l.copy()\n",
    "        del train[i:i + z]\n",
    "        yield train, test\n",
    "\n",
    "\n",
    "        \n",
    "class Inputs:\n",
    "    def __init__(self, train: Collection, dev: Collection, test: Collection):\n",
    "        self.train: Collection = train.copy()\n",
    "        self.dev: Collection = dev.copy()\n",
    "        self.test: Collection = test.copy()\n",
    "        self.all_train: Collection = Collection(self.train.all + self.dev.all)\n",
    "\n",
    "    @classmethod\n",
    "    def train_input(cls, folder: str, n_splits=5):\n",
    "        train = Collection.read(rf'trainlabeledBow.feat').shuffle()\n",
    "\n",
    "        for train2, dev in multi_vald(train.all, n_splits):\n",
    "            yield cls(Collection(train2), Collection(dev), Collection([]))\n",
    "\n",
    "    @classmethod\n",
    "    def fetch(cls, folder: str, n_splits=5):\n",
    "        train = Collection.read(rf'trainlabeledBow.feat')\n",
    "        test = Collection.read(rf'testlabeledBow.feat')\n",
    "        review_set = train.all + test.all\n",
    "        shuffle(review_set)\n",
    "\n",
    "        for train, test in multi_vald(review_set, n_splits):\n",
    "            yield cls(Collection(train), Collection([]), Collection(test))\n",
    "\n",
    "    def copy(self):\n",
    "        return Inputs(self.train, self.dev, self.test)    \n",
    "\n",
    "def mean(models: list, data: list, smooth: float = 1, min_app: float = 0):\n",
    "    accuracy = 0\n",
    "    for i, model in enumerate(models):\n",
    "        cur = model.accuracy(data[i], smooth, min_app)\n",
    "        accuracy += cur\n",
    "    accuracy /= len(models)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "\n",
    "class NBclass:\n",
    "    def __init__(self, data: Collection, new_gen_vocab: complete_imdb_vocab):\n",
    "        self.data: Collection = data.copy()\n",
    "        self.new_gen_vocab = new_gen_vocab\n",
    "\n",
    "        self.calculate(self.data)\n",
    "\n",
    "    def calculate(self, reviews: Collection):\n",
    "        self.words = set()\n",
    "        for review in reviews.all:\n",
    "            self.words.update(review)\n",
    "\n",
    "        self.positive = {word: 0 for word in self.words}\n",
    "        self.negative = {word: 0 for word in self.words}\n",
    "\n",
    "        for review in reviews.pos_review:\n",
    "            for word in review:\n",
    "                self.positive[word] += 1\n",
    "        for review in reviews.neg_review:\n",
    "            for word in review:\n",
    "                self.negative[word] += 1\n",
    "\n",
    "    def prediction(self, review: Features, smooth: float = 0, min_app: float = 0):\n",
    "        pred_pos, pred_neg = len(self.data.pos_review), len(self.data.neg_review)\n",
    "        min_total = len(self.data.all) * min_app\n",
    "        for word in review:\n",
    "            if self.new_gen_vocab.indexed_stpwrds(word):\n",
    "                continue\n",
    "\n",
    "            pos_review = self.positive.get(word, 0)  \n",
    "            neg_review = self.negative.get(word, 0)  \n",
    "            total = pos_review + neg_review\n",
    "            if total == 0 or total < min_total: \n",
    "                continue\n",
    "\n",
    "            pred_pos *= (pos_review + smooth) / (total + smooth * 2)  \n",
    "            pred_neg *= (neg_review + smooth) / (total + smooth * 2)\n",
    "            if pred_pos == 0 or pred_neg == 0:\n",
    "                break\n",
    "\n",
    "        return 1 if pred_pos > pred_neg else -1\n",
    "\n",
    "    def accuracy(self, reviews: Collection, smooth: float = 0, min_app: float = 0):\n",
    "        accurate, total = 0, 0\n",
    "        for review in reviews:\n",
    "            if review.num_rate == self.prediction(review, smooth, min_app):\n",
    "                accurate += 1\n",
    "            total += 1\n",
    "\n",
    "        return accurate / total\n",
    "\n",
    "    def most_freq(self, top_count=10, min_app=0.001):\n",
    "        total_pos, total_neg = len(self.data.pos_review), len(self.data.neg_review)\n",
    "        freq_pos = total_pos / (total_pos + total_neg)\n",
    "        freq_neg = total_neg / (total_pos + total_neg)\n",
    "\n",
    "        pred_pos, pred_neg, polarity = {}, {}, {}\n",
    "        for word in self.words:\n",
    "            if self.new_gen_vocab.indexed_stpwrds(word):\n",
    "                continue\n",
    "\n",
    "            num_pos = self.positive.get(word, 0)\n",
    "            num_neg = self.negative.get(word, 0)\n",
    "            count_total = num_pos + num_neg\n",
    "            if count_total < len(self.data.all) * min_app:\n",
    "                continue\n",
    "\n",
    "            str_word = self.new_gen_vocab.words[word]\n",
    "            pred_pos[str_word] = freq_pos * num_pos / count_total\n",
    "            pred_neg[str_word] = freq_neg * num_neg / count_total\n",
    "            polarity[str_word] = (num_pos - num_neg ) / count_total\n",
    "\n",
    "        top_pos = sorted(pred_pos.items(), key=lambda item: item[1], reverse=True)\n",
    "        pos_words = [x[0] for x in top_pos]\n",
    "        top_neg = sorted(pred_neg.items(), key=lambda item: item[1], reverse=True)\n",
    "        neg_words = [x[0] for x in top_neg]\n",
    "\n",
    "        return pos_words[:top_count], neg_words[:top_count]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>New Vocabulary generated using ntlk to remove all the stopwords.</B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_gen_vocab = complete_imdb_vocab(r'imdb.vocab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopwords: {'down', 'had', 'how', 'that', 'each', 'on', 'too', 'then', 'were', \"haven't\", 'aren', 'be', 'd', 'further', 'as', 'nor', 'doing', 'more', \"doesn't\", 'above', 'are', 'about', 'yourself', \"didn't\", 'his', 'to', 'these', 'they', 'by', 'needn', 'once', 'an', 'because', 'doesn', 'haven', \"shan't\", 'at', 'them', 'theirs', 'over', 'until', 'before', \"should've\", 'which', 'what', 'been', 'you', 'me', 'did', 'y', 'him', 'hadn', \"you've\", 'she', 'do', 'couldn', 'shouldn', 'and', 'there', 'hers', 'its', 'won', \"she's\", \"that'll\", 'weren', 'between', 'ma', 'below', \"it's\", 'our', 'all', 'most', 'when', 'but', 'own', 'he', \"mustn't\", 'so', 'their', \"couldn't\", 'of', \"needn't\", 'here', 'mightn', 'out', 'through', 'shan', 'has', 'for', 'both', 'don', 'why', 'yourselves', 'now', 'her', 'same', 'your', 'having', 'themselves', 'a', 'herself', 'm', \"mightn't\", 'into', 'hasn', 'very', 'whom', 'this', 's', \"you'll\", 'during', 'than', \"weren't\", 't', 'll', 'such', 'off', \"shouldn't\", \"wasn't\", 'ours', 'other', 're', \"hasn't\", 'just', 'only', 'have', \"don't\", 'my', 'no', 'being', 'am', 'again', 'does', 'didn', 'myself', \"won't\", \"hadn't\", 'the', 'in', 've', 'itself', 'some', 'can', 'it', 'should', 'o', \"isn't\", 'against', 'after', 'those', 'i', 'isn', 'ain', \"you'd\", 'ourselves', 'who', \"wouldn't\", 'himself', 'if', 'up', 'any', \"aren't\", 'wasn', 'while', 'where', 'was', 'wouldn', 'with', 'from', 'will', 'yours', 'or', 'not', 'we', 'under', 'few', 'is', 'mustn', \"you're\"}\n"
     ]
    }
   ],
   "source": [
    "print(f'Stopwords: {new_gen_vocab.stopwords}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>Models generated for 5-fold cross-validation</B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 models created for cross-validation\n"
     ]
    }
   ],
   "source": [
    "levels = 5\n",
    "dataset = list(Inputs.train_input('aclImdb', levels))\n",
    "models = [NBclass(x.train, new_gen_vocab) for x in dataset]\n",
    "print(f'{len(models)} models created for cross-validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = dataset[0].all_train\n",
    "index_the = new_gen_vocab.word_index('the')\n",
    "index_magnificent = new_gen_vocab.word_index('magnificent')\n",
    "index_poor = new_gen_vocab.word_index('poor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>Calculating Probability for \"the\" ; P[the] = num of documents containing ‘the’ / all documents</B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P[\"the\"] = 0.9917\n"
     ]
    }
   ],
   "source": [
    "print(f'P[\"the\"] = {reviews.total_count(index_the) / len(reviews.all):0.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also calculating probablity of two exteremely positve and negative words <i>\"magnificent\"</i> and <i>\"poor\"</i> respectively, just to see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P[\"magnificent\"] = 0.0097\n",
      "P[\"poor\"] = 0.0635\n"
     ]
    }
   ],
   "source": [
    "print(f'P[\"magnificent\"] = {reviews.total_count(index_magnificent) / len(reviews.all):0.4f}')\n",
    "print(f'P[\"poor\"] = {reviews.total_count(index_poor) / len(reviews.all):0.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating <B>P[“the” | Positive]</B> = # of positive documents containing “the” / num of all positive documents.\n",
    "\n",
    "Calculating <B>P[“the” | Negative]</B> = # of positive documents containing “the” / num of all positive documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P[\"the\" | Positive] = 0.9905\n",
      "P[\"the\" | Negative] = 0.9929\n"
     ]
    }
   ],
   "source": [
    "print(f'P[\"the\" | Positive] = {reviews.count_positive(index_the) / len(reviews.pos_review):0.4f}')\n",
    "print(f'P[\"the\" | Negative] = {reviews.count_negative(index_the) / len(reviews.pos_review):0.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing the same for <i>\"magnificent\"</i> and <i>\"poor\"</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P[\"magnificent\" | Positive] = 0.0159\n",
      "P[\"magnificent\" | Negative] = 0.0035\n",
      "P[\"poor\" | Positive] = 0.0294\n",
      "P[\"poor\" | Negative] = 0.0975\n"
     ]
    }
   ],
   "source": [
    "print(f'P[\"magnificent\" | Positive] = {reviews.count_positive(index_magnificent) / len(reviews.pos_review):0.4f}')\n",
    "print(f'P[\"magnificent\" | Negative] = {reviews.count_negative(index_magnificent) / len(reviews.pos_review):0.4f}')\n",
    "\n",
    "print(f'P[\"poor\" | Positive] = {reviews.count_positive(index_poor) / len(reviews.pos_review):0.4f}')\n",
    "print(f'P[\"poor\" | Negative] = {reviews.count_negative(index_poor) / len(reviews.pos_review):0.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>Calculation avegrage accuracy on development data models without any smoothing and with zero minimum appearance.</B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for dev data = 0.7514\n"
     ]
    }
   ],
   "source": [
    "dev_data = [x.dev for x in dataset]\n",
    "accuracy = mean(models, dev_data, smooth=0, min_app=0)\n",
    "print(f'Average accuracy for dev data = {accuracy:0.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>Calculating the average accuracy on development data without any smoothing but minimum 5 appearances of a word.</B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy = 0.8343\n"
     ]
    }
   ],
   "source": [
    "dev_data = [x.dev for x in dataset]\n",
    "accuracy = mean(models, dev_data, smooth=0, min_app=0.00025)\n",
    "print(f'Average accuracy = {accuracy:0.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>Calculating the average accuracy on development data while experimenting with smoothing hyperparameters in range <i>[0, 1]</i> with step size <i>\"0.1\"</i></B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.83432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.85536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <td>0.85596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3</th>\n",
       "      <td>0.85624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>0.85636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>0.85644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>0.85648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.7</th>\n",
       "      <td>0.85676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>0.85696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9</th>\n",
       "      <td>0.85740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.85752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Accuracy\n",
       "0.0   0.83432\n",
       "0.1   0.85536\n",
       "0.2   0.85596\n",
       "0.3   0.85624\n",
       "0.4   0.85636\n",
       "0.5   0.85644\n",
       "0.6   0.85648\n",
       "0.7   0.85676\n",
       "0.8   0.85696\n",
       "0.9   0.85740\n",
       "1.0   0.85752"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyp_par = {}\n",
    "for i in (x * 0.1 for x in range(0, 11)):\n",
    "    hyp_par[i] = mean(models, dev_data, smooth=i, min_app=0.00025)\n",
    "smoothing_accuracies = pd.DataFrame.from_dict(hyp_par, orient='index', columns=['Accuracy'])\n",
    "smoothing_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>The accuracy values didn't really change after <b>\"0.1\"</b>, so it's clear that <b>Too-much of smoothing doesn't really have a drastic effect on accuracy</b></i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>For calculation final accuracy on our test-data smoothing value is set to <i>\"0.5\"</i> and minimum appearance is set to <i>\"5\"</i> times.</B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy on test_data = 0.8566\n"
     ]
    }
   ],
   "source": [
    "dataset = list(Inputs.fetch('aclImdb', levels))\n",
    "models = [NBclass(x.train, new_gen_vocab) for x in dataset]\n",
    "test_data = [x.test for x in dataset]\n",
    "accuracy = mean(models, test_data, smooth=0.5, min_app=0.00025)\n",
    "print(f'Final accuracy on test_data = {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>Lastly, the TOP 10 Positive and Negative words</B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Positive words:\n",
      "['flawless', 'superbly', 'captures', 'wonderfully', 'must-see', 'timeless', 'understated', 'perfection', 'loneliness', 'underrated']\n",
      "\n",
      "\n",
      "Top 10 Negative words:\n",
      "['stinker', 'ugh', 'incoherent', 'waste', 'unfunny', 'unwatchable', 'wasting', 'atrocious', 'sub-par', 'redeeming']\n"
     ]
    }
   ],
   "source": [
    "pos_words, neg_words = models[0].most_freq(top_count=10, min_app=0.0025)\n",
    "print(f'Top 10 Positive words:\\n{pos_words}\\n\\n')\n",
    "print(f'Top 10 Negative words:\\n{neg_words}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
